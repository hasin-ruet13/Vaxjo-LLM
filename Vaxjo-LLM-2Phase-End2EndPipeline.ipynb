{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47b5a90a-3cce-4c17-8b53-58eeea3fa9f5",
   "metadata": {},
   "source": [
    "**Supplementary File 1. LLM code.** Complete code used to implement the two-phase LLM workflow for extracting and summarizing vaccine adjuvant mechanisms from PubMed abstracts. The file includes the full extraction module and the secondary summarization module used in Vaxjo 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e02f19f-e8b8-461a-a7fd-20e637e8c595",
   "metadata": {},
   "source": [
    "##### *Phase I: Llama Inferencing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433d82c4-5b21-4196-8ba0-c10392a5451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22eeee3-c37d-4901-9c43-7bc415ef350b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Replace 'your_token_here' with your actual Hugging Face token\n",
    "from huggingface_hub import login\n",
    "import os\n",
    "\n",
    "token = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "if token is None:\n",
    "    raise ValueError(\"HF_TOKEN environment variable not set.\")\n",
    "\n",
    "login(token=token)\n",
    "\n",
    "print(\"Successfully logged in!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed439a53-8aee-41fa-b42c-f32f95d0463f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_gpus = torch.cuda.device_count()\n",
    "print(\"N GPUS: \", n_gpus)\n",
    "\n",
    "# Set memory limits per GPU\n",
    "model_vram_limit_mib = 8192  #12000\n",
    "max_memory = f'{model_vram_limit_mib}MiB'\n",
    "max_memory_dict = {i: max_memory for i in range(n_gpus)}\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "# Load model and tokenizer with memory limits\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    max_memory=max_memory_dict\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# Now create the pipeline using pre-loaded model/tokenizer\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec775719-b8e0-418d-ba48-6813e94a5aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Custom system prompt for extracting adjuvants and immune mechanisms\n",
    "system_prompt = (\n",
    "        \"\"\"You are a biomedical assistant with expertise in immunology. Extract all substances explicitly described as vaccine adjuvants from the input article.\n",
    "\n",
    "For each adjuvant, extract the following:\n",
    "- \"adjuvant\": The name of the adjuvant (e.g., Alum, MPLA, QS-21)\n",
    "- \"immune_response_mechanism\": A brief description of how the adjuvant works to stimulate or enhance the immune response, as described in the text.\n",
    "\n",
    "Guidelines:\n",
    "- Include only substances that are explicitly described as adjuvants in the input.\n",
    "- Do not include delivery systems (e.g., liposomes, virosomes, VLPs) unless they are clearly described as adjuvants.\n",
    "- Do not infer or guess mechanisms that are not mentioned; leave them empty if not described.\n",
    "- If no adjuvants are found, say 'No adjuvants mentioned.\n",
    "- Return valid JSON in the following format:\n",
    "\n",
    "\n",
    "[\n",
    "  {\n",
    "    \"adjuvant\": \"Alum\",\n",
    "    \"immune_response_mechanism\": \"Activates NLRP3 inflammasome and forms a depot for slow antigen release.\"\n",
    "  },\n",
    "  {\n",
    "    \"adjuvant\": \"MPLA\",\n",
    "    \"immune_response_mechanism\": \"Engages TLR4 pathway to promote Th1 responses.\"\n",
    "  }\n",
    "]\"\"\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1315444e-cac6-40de-9c2f-7802e71cf948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import gc\n",
    "from datetime import datetime\n",
    "\n",
    "def extract_and_save_adjuvant_response_text_from_string(\n",
    "    pmc_id: str,\n",
    "    text: str,\n",
    "    system_prompt: str,\n",
    "    pipe,\n",
    "    output_file: str,\n",
    "    max_new_tokens: int = 512\n",
    "):\n",
    "    \"\"\"\n",
    "    Processes a single abstract string and saves the response with PMID to output_file.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": text},\n",
    "    ]\n",
    "    outputs = pipe(messages, max_new_tokens=max_new_tokens)\n",
    "    response_text = outputs[0][\"generated_text\"][-1][\"content\"]\n",
    "    with open(output_file, \"a\", encoding=\"utf-8\") as out_f:\n",
    "        out_f.write(f\"=== {pmc_id} ===\\n\")\n",
    "        out_f.write(response_text.strip() + \"\\n\\n\")\n",
    "    print(f\"Saved response for {pmc_id} to {output_file}\")\n",
    "\n",
    "def process_all_papers(\n",
    "    input_json_file: str,\n",
    "    system_prompt: str,\n",
    "    pipe,\n",
    "    output_txt_file: str,\n",
    "    log_csv_file: str,\n",
    "    max_new_tokens: int = 512\n",
    "):\n",
    "    \"\"\"\n",
    "    Processes all abstracts from a JSON file and logs each result (success/failure) to a CSV.\n",
    "    Args:\n",
    "        input_json_file (str): Path to input JSON file with {PMID: {title, abstract}} entries.\n",
    "        system_prompt (str): System prompt for the LLM.\n",
    "        pipe: Hugging Face pipeline object.\n",
    "        output_txt_file (str): Path to save model responses (plain text).\n",
    "        log_csv_file (str): Path to save logs (CSV).\n",
    "        max_new_tokens (int): Generation token limit.\n",
    "    \"\"\"\n",
    "    # Read all abstracts into a dict\n",
    "    with open(input_json_file, encoding=\"utf-8\") as f:\n",
    "        papers_dict = json.load(f)\n",
    "\n",
    "    print(f\"Found {len(papers_dict)} papers. Starting extraction...\\n\")\n",
    "\n",
    "    # Prepare log CSV (write headers if file doesn't exist)\n",
    "    log_exists = os.path.exists(log_csv_file)\n",
    "    with open(log_csv_file, \"a\", newline='', encoding=\"utf-8\") as log_f:\n",
    "        log_writer = csv.writer(log_f)\n",
    "        if not log_exists:\n",
    "            log_writer.writerow([\"PMID\", \"Status\", \"Message\", \"Timestamp\"])\n",
    "\n",
    "        for i, (pmcid, paper_data) in enumerate(papers_dict.items(), 1):\n",
    "            abstract_text = paper_data.get(\"abstract\", \"\") or \"\"\n",
    "            status = \"success\"\n",
    "            message = \"Processed successfully\"\n",
    "            try:\n",
    "                extract_and_save_adjuvant_response_text_from_string(\n",
    "                    pmcid, abstract_text, system_prompt, pipe, output_txt_file, max_new_tokens\n",
    "                )\n",
    "            except Exception as e:\n",
    "                status = \"error\"\n",
    "                message = str(e)[:500]\n",
    "                print(f\"❌ Error processing PMID {pmcid}: {message}\")\n",
    "            else:\n",
    "                print(f\"✅ [{i}/{len(papers_dict)}] Processed PMID {pmcid}\")\n",
    "            finally:\n",
    "                log_writer.writerow([pmcid, status, message, datetime.now().isoformat()])\n",
    "                log_f.flush()\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2254c2da-5b5c-48ff-b617-5a1ac88c410a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import csv\n",
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "input_json_file = \"Dataset/Vaxjo/All PMID abstracts.txt\"  # should contain JSON, not plain text\n",
    "output_txt_file = \"Outputs/Vaxjo-LLM-Phase I-Response.txt\"\n",
    "log_csv_file = \"Outputs/Vaxjo_PMIDs_adjuvant_log.csv\"\n",
    "\n",
    "process_all_papers(\n",
    "    input_json_file,\n",
    "    system_prompt,\n",
    "    pipe,\n",
    "    output_txt_file,\n",
    "    log_csv_file,\n",
    "    max_new_tokens=512\n",
    ")\n",
    "print(\"Phase I LLM inferencing complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f68ed98-f32e-4a75-8703-c21a84da9511",
   "metadata": {},
   "source": [
    "##### *Phase I - Processing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea56db01-8ae6-4775-b786-b042d2f3b31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load the content from the text file\n",
    "with open(\"Outputs/Vaxjo-LLM-Phase I-Response.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Extract each PMID block\n",
    "entries = re.split(r'===\\s+(\\d+)\\s+===', content)[1:]\n",
    "pmid_ids = entries[::2]   # PMIDs\n",
    "texts = entries[1::2]    # Corresponding text blocks\n",
    "\n",
    "# Extract data\n",
    "data = []\n",
    "for pmid_id, text in zip(pmid_ids, texts):\n",
    "    if \"No adjuvants mentioned.\" in text:\n",
    "        continue\n",
    "    # Find JSON-like blocks\n",
    "    json_blocks = re.findall(r\"\\[\\s*{.*?}\\s*]\", text, re.DOTALL)\n",
    "    for block in json_blocks:\n",
    "        try:\n",
    "            adjuvant_list = json.loads(block)\n",
    "            for item in adjuvant_list:\n",
    "                data.append({\n",
    "                    \"PMID\": pmid_id,\n",
    "                    \"adjuvant\": item.get(\"adjuvant\"),\n",
    "                    \"immune_response_mechanism\": item.get(\"immune_response_mechanism\")\n",
    "                })\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "\n",
    "# Save to CSV\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"Outputs/Vaxjo_PMIDs_adjuvant_extracted.csv\", index=False)\n",
    "\n",
    "print(\"Extraction complete. Saved to 'Vaxjo_PMIDs_adjuvant_extracted.csv'.\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31655c42-f643-4f18-9a28-6dc1bfc8ce5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique adjuvants\n",
    "unique_adjuvants = df[\"adjuvant\"].nunique()\n",
    "print(f\"Number of unique adjuvants: {unique_adjuvants}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d782dd3d-f00f-44f6-ae62-8960946e0f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find unique immune response mechanisms containing the word \"not\" (case-insensitive)\n",
    "mechanisms = df[\"immune_response_mechanism\"].dropna().unique()\n",
    "\n",
    "mechanisms_with_not_none = [\n",
    "    m for m in mechanisms if (\"not \" in m.lower() or \"none \" in m.lower() in m.lower())\n",
    "]\n",
    "\n",
    "for mechanism in mechanisms_with_not_none:\n",
    "    print(mechanism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d37069b-ed3c-483e-96cb-50c206e5581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_valid_keywords = [\n",
    "    \"None mentioned\",\n",
    "\"Not explicitly described\",\n",
    "\"None mentioned.\",\n",
    "\"Not specified\",\n",
    "\"None described\",\n",
    "\"Not explicitly described in the text\",\n",
    "\"Mechanism of action not yet completely known, but it is comprised of Quillaja saponins, cholesterol and phospholipid, and induces recruitment of leukocytes to draining lymph nodes (dLNs) and spleen, activation of central immune cells, and elevation of cytokines and co-stimulatory molecules.\",\n",
    "\"None specified\",\n",
    "\"Not mentioned\",\n",
    "\"Mechanism not explicitly described\",\n",
    "\"Not explicitly stated, but based on the context, it appears to stimulate a robust immune response by enhancing the production of various cytokines and antibody-secreting cells.\",\n",
    "\"Not specified in the text.\",\n",
    "\"Not explicitly described, but it is known that aluminum salts activate NLRP3 inflammasome and form a depot for slow antigen release.\",\n",
    "\"Not explicitly described, but it is known that saponins like QS21 can stimulate immune responses by interacting with TLR4 and TLR8.\",\n",
    "\"Not described\",\n",
    "\"Mechanism not described\",\n",
    "\"Not explicitly described, left blank.\"\n",
    "]\n",
    "\n",
    "\n",
    "# Drop rows with NaN or empty strings (after stripping whitespace)\n",
    "df_cleaned = df[df[\"immune_response_mechanism\"].notna()].copy()\n",
    "df_cleaned = df_cleaned[df_cleaned[\"immune_response_mechanism\"].str.strip() != \"\"]\n",
    "\n",
    "# Remove rows containing any invalid keyword (case-insensitive)\n",
    "df_cleaned = df_cleaned[\n",
    "    ~df_cleaned[\"immune_response_mechanism\"].str.lower().apply(\n",
    "        lambda x: any(keyword in x for keyword in not_valid_keywords)\n",
    "    )\n",
    "].reset_index(drop=True)\n",
    "\n",
    "# Save to CSV\n",
    "df_cleaned.to_csv(\"Outputs/Vaxjo_PMIDs_adjuvant_extracted_clean.csv\", index=False)\n",
    "\n",
    "# Preview the result\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736515bd-2cee-4bc2-9939-06151aa352c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and print the sorted list of unique adjuvant names\n",
    "unique_adjuvant_names = sorted(df_cleaned[\"adjuvant\"].unique())\n",
    "print(\"Unique adjuvants:\")\n",
    "for name in unique_adjuvant_names:\n",
    "    print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dd6539-fc6b-4081-965e-da60e0736c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    # ---- Adjuplex / ADJ ----\n",
    "    \"ADJ\": \"Adjuplex (ADJ)\",\n",
    "\n",
    "    # ---- Alum / Aluminum hydroxide family (exact naming variants only) ----\n",
    "    \"Alum\": \"Alum (aluminum hydroxide)\",\n",
    "    \"Al(OH)3\": \"Alum (aluminum hydroxide)\",\n",
    "    \"Alhydrogel\": \"Alum (aluminum hydroxide)\", #commercial brand name for an aluminum hydroxide gel suspension\n",
    "    \"Aluminium Hydroxide (AH)\": \"Alum (aluminum hydroxide)\",\n",
    "    \"Aluminium hydroxide\": \"Alum (aluminum hydroxide)\",\n",
    "    \"Aluminum Hydroxide\": \"Alum (aluminum hydroxide)\",\n",
    "    \"Aluminum Hydroxide (AH)\": \"Alum (aluminum hydroxide)\",\n",
    "    \"Aluminum hydroxide\": \"Alum (aluminum hydroxide)\",\n",
    "    \"Aluminum hydroxide (AH)\": \"Alum (aluminum hydroxide)\",\n",
    "    \"Aluminum hydroxide (Alum)\": \"Alum (aluminum hydroxide)\",\n",
    "    \"Aluminum oxyhydroxide\": \"Alum (aluminum hydroxide)\", #Aluminum oxyhydroxide is the formal chemical name for the hydrated crystalline species often used in alum adjuvants (sometimes cited as boehmite-like AlO(OH)), which is the same active form as in common alum formulations. So mapping to “Alum (aluminum hydroxide)” is also correct.\n",
    "    # ---- Advax / delta inulin (brand vs generic, diacritics, ™/®) ----\n",
    "    \"Advax\": \"Advax (delta inulin)\",\n",
    "    \"Advax delta inulin\": \"Advax (delta inulin)\",\n",
    "    \"Advax® delta inulin\": \"Advax (delta inulin)\",\n",
    "    \"Advax™\": \"Advax (delta inulin)\",\n",
    "    \"Delta Inulin (DI)\": \"Advax (delta inulin)\",\n",
    "    \"Delta inulin\": \"Advax (delta inulin)\",\n",
    "    \"delta inulin\": \"Advax (delta inulin)\",\n",
    "    \"delta inulin (DI)\": \"Advax (delta inulin)\",\n",
    "    \"delta inulin adjuvant (Advax™)\": \"Advax (delta inulin)\",\n",
    "    \"δ-inulin\": \"Advax (delta inulin)\",\n",
    "    \"delta-inulin\": \"Advax (delta inulin)\",\n",
    "\n",
    "    # Keep specific Advax *formulations* distinct:\n",
    "    # Advax-2 / -M / -P / -SM / CpG / CpG55.2 etc. are NOT collapsed.\n",
    "\n",
    "    # ---- BECC spelling/spacing ----\n",
    "    \"BECC 438\": \"BECC438\",\n",
    "    \"BECC 470\": \"BECC470\",\n",
    "\n",
    "    # ---- Calcium phosphate shorthand ----\n",
    "    \"CAP\": \"Calcium Phosphate (CAP)\",\n",
    "\n",
    "    # ---- CAF01 encoding variant ----\n",
    "    \"CAF\\u00b01\": \"CAF01\",\n",
    "\n",
    "    # ---- Cholera toxin naming ----\n",
    "    \"Cholera toxin\": \"Cholera toxin (CT)\",\n",
    "\n",
    "    # ---- Compound 48/80 naming ----\n",
    "    \"C48/80\": \"Compound 48/80 (C48/80)\",\n",
    "\n",
    "    # ---- CoVaccine HT trademark ----\n",
    "    \"CoVaccine HT™\": \"CoVaccine HT\",\n",
    "\n",
    "    # ---- CpG ODN (shorthands & plurals used as the same thing here) ----\n",
    "    \"CpG\": \"CpG ODN\",\n",
    "    \"CpG ODNs\": \"CpG ODN\",\n",
    "    #\"CpG motifs\": \"CpG ODN\",\n",
    "    \"CpG oligodeoxynucleotide (CpG-ODN)\": \"CpG ODN\",\n",
    "    \"CpG-ODN\": \"CpG ODN\",\n",
    "\n",
    "    # Keep specific sequences distinct (not collapsed):\n",
    "    # \"CpG ODN 1826\", \"CpG M362\", \"ODN2006\" remain separate.\n",
    "\n",
    "\n",
    "    \"Complete Freund's adjuvant\": \"Complete Freund's Adjuvant (CFA)\",\n",
    "    \n",
    "    # ---- EM-005 aka GLA-SE ----\n",
    "    \"EM-005 (GLA-SE)\": \"GLA-SE\",\n",
    "\n",
    "    # ---- Flagellin (case only) ----\n",
    "    \"flagellin\": \"Flagellin\",\n",
    "\n",
    "    # (FliC, FlaB kept distinct—specific flagellins.)\n",
    "\n",
    "    # ---- GLA naming variants ----\n",
    "    \"Glucopyranosyl Lipid Adjuvant\": \"GLA\",\n",
    "    \"Glucopyranosyl Lipid Adjuvant (GLA)\": \"GLA\",\n",
    "    \"Glucopyranosyl lipid A\": \"GLA\",\n",
    "    #\"Glucopyranosyl lipid A (G100)\": \"GLA\",\n",
    "    \"Glucopyranosyl lipid adjuvant (GLA)\": \"GLA\",\n",
    "    \"ID93/glucopyranosyl lipid adjuvant (GLA)\": \"GLA\",\n",
    "    # GLA-AF / GLA-SE / GLA-LSQ are formulations—kept distinct.\n",
    "    \n",
    "    \"GLA-SE (components included: glucopyranosyl lipid A, squalene emulsion)\": \"GLA-SE\",\n",
    "    \"GLA-squalene emulsion\": \"GLA-SE\",\n",
    "    \"Glucopyranosyl lipid A (G100)\": \"GLA\",\n",
    "    \n",
    "    # ---- IFN naming (alpha/beta symbol) ----\n",
    "    \"IFN-alpha\": \"IFN-α\",\n",
    "    \"IFNβ\": \"IFN-β\",\n",
    "\n",
    "    # ---- Imiquimod alias ----\n",
    "    \"imiquimod (R837)\": \"Imiquimod (R837)\",\n",
    "    \"Imiquimod\": \"Imiquimod (R837)\",\n",
    "\n",
    "    # ---- Matrix-M trademark ----\n",
    "    \"Matrix-M™\": \"Matrix-M\",\n",
    "\n",
    "    # ---- MCT trademark ----\n",
    "    \"MCT®\": \"MCT\",\n",
    "\n",
    "    # ---- MPL naming variants ----\n",
    "    '''\"MPL\": \"MPL (monophosphoryl lipid A)\",\n",
    "    \"MPL®\": \"MPL (monophosphoryl lipid A)\",\n",
    "    \"Monophosphoryl lipid\": \"MPL (monophosphoryl lipid A)\",\n",
    "    \"Monophosphoryl lipid A (MPLA)\": \"MPLA\",'''\n",
    "    \n",
    "    # Keep \"MPLA\" as is (canonical already).\n",
    "    \"MPL\": \"MPL (monophosphoryl lipid A)\",\n",
    "    \"MPL®\": \"MPL (monophosphoryl lipid A)\",\n",
    "    \"Monophosphoryl lipid\": \"MPL (monophosphoryl lipid A)\",\n",
    "    \"Monophosphoryl lipid A (MPLA)\": \"MPL (monophosphoryl lipid A)\",\n",
    "\n",
    "    \"MPL (monophosphoryl lipid A)\": \"MPLA\",\n",
    "    \"MPL\": \"MPLA\",   # redundant safety check, in case not yet mapped\n",
    "    \n",
    "    # \"MPLA\" stays as is (already canonical).\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"M7\": \"Mastoparan-7 (M7)\",\n",
    "\n",
    "    \n",
    "    # Keep MPL-SE / MPL+TDM / MPL/DDA distinct (formulations/combinations).\n",
    "\n",
    "    # ---- Montanide ISA 51 spacing ----\n",
    "    \"Montanide ISA-51\": \"Montanide ISA 51\",\n",
    "    \"Montanide ISA51\": \"Montanide ISA 51\",\n",
    "    \n",
    "    # --- Mastoparan naming ---\n",
    "    \"Mastoparan 7\": \"Mastoparan-7 (M7)\",\n",
    "   \n",
    "    # ---- PCL abbreviation expansion ----\n",
    "    \"PCL/chitosan NPs\": \"poly-ϵ-caprolactone/chitosan NPs\",\n",
    "\n",
    "    # ---- Poly(I:C) case ----\n",
    "    \"poly(I:C)\": \"Poly(I:C)\",\n",
    "\n",
    "    # ---- Polyclonal Antibody Stimulator naming ----\n",
    "    \"polyclonal antibody stimulator-PAS\": \"Polyclonal Antibody Stimulator (PAS)\",\n",
    "\n",
    "    # ---- QS-21 dash/spacing ----\n",
    "    \"QS21\": \"QS-21\",\n",
    "\n",
    "    # ---- R848 (resiquimod) alias ----\n",
    "    \"R848\": \"Resiquimod (R848)\",\n",
    "    \"resiquimod\": \"Resiquimod (R848)\",\n",
    "\n",
    "    # ---- SE (squalene emulsion) naming (keep brands separate like MF59/AS03) ----\n",
    "    \"Squalene-based oil-in-water emulsion system (SE)\": \"SE\",\n",
    "    \"squalene oil-in-water emulsion (SE)\": \"SE\",\n",
    "\n",
    "    # ---- SWE (Sepivac SWE) naming ----\n",
    "    \"Sepivac SWE\": \"SWE\",\n",
    "    \"SEPIVAC SWETM\": \"SWE\",\n",
    "\n",
    "    # ---- Squalene case only ----\n",
    "    \"squalene\": \"Squalene\",\n",
    "\n",
    "    # ---- TDM (trehalose-6,6'-dimycolate) spelling variants ----\n",
    "    \"6,6'-trehalose dimycolate (TDM)\": \"Trehalose-6,6'-dimycolate (TDM)\",\n",
    "\n",
    "    # ---- α-GalCer naming variants ----\n",
    "    \"α-Galactosylceramide (α-GC)\": \"α-GalCer\",\n",
    "    \"α-Galactosylceramide (αGalCer)\": \"α-GalCer\",\n",
    "}\n",
    "df_cleaned[\"adjuvant_canonical\"] = df_cleaned[\"adjuvant\"].replace(mapping)\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc417b3f-0179-4f6b-b9be-1ff172ca9637",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before:\", df_cleaned[\"adjuvant\"].nunique())\n",
    "print(\"After :\", df_cleaned[\"adjuvant_canonical\"].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dc4204-16d5-47f3-8eaf-6eaaf88d7a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and print the sorted list of unique adjuvant names\n",
    "unique_adjuvant_names_canonical = sorted(df_cleaned[\"adjuvant_canonical\"].unique())\n",
    "print(\"Unique adjuvants_canonical:\")\n",
    "for name in unique_adjuvant_names_canonical:\n",
    "    print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12c0d9c-5009-40cd-8acf-fb1b0bbe3641",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = (\n",
    "    df_cleaned\n",
    "    .assign(immune_response_mechanism=lambda x: x[\"immune_response_mechanism\"] + \" [\" + x[\"PMID\"].astype(str) + \"]\")\n",
    "    .groupby(\"adjuvant_canonical\")[\"immune_response_mechanism\"]\n",
    "    .agg(lambda x: \" | \".join(sorted(set(x))))\n",
    "    .reset_index()\n",
    "    .sort_values(by=\"adjuvant_canonical\", key=lambda s: s.str.lower())\n",
    ")\n",
    "\n",
    "df_grouped.to_csv(\"Outputs/Vaxjo_PMIDs_adjuvant_mechanism_collapsed.csv\", index=False)\n",
    "df_grouped\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c77bbb4-c509-4983-88f1-4f05e58cd692",
   "metadata": {},
   "source": [
    "##### *Phase II: Llama Inferencing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd478aa-0613-4cb7-bf08-51e37d9d4bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "system_prompt = \"\"\"You are an expert immunologist and biomedical research assistant.\n",
    "TASK: Analyze the provided text on a vaccine adjuvant's immune response. Extract and structure the key mechanistic information according to the specified JSON schema.\n",
    "\n",
    "## Instructions for the \"summary\" field:\n",
    "- **Synthesize the information into a cohesive, mechanistic narrative of approximately 3-5 sentences.**\n",
    "- This summary should not be a simple list of facts. Instead, it should describe the sequence of immunological events initiated by the adjuvant.\n",
    "- For example, describe how the adjuvant is initially sensed (e.g., by PRRs like TLRs), how this leads to innate cell activation (e.g., dendritic cells), and how this subsequently shapes the adaptive response (e.g., T cell polarization and antibody production).\n",
    "- Integrate the corresponding PMIDs directly into the text immediately following the claims they support.\n",
    "\n",
    "## Instructions for the \"mechanism_subtypes\" field:\n",
    "- Identify **every distinct** immunological mechanism.\n",
    "- For each identified subtype, list all unique PMIDs cited as evidence for it in the source text.\n",
    "- Do not merge related subtypes; for example, if both \"dendritic cell\" and \"TLR4\" are mentioned, create separate entries for each.\n",
    "\n",
    "## General Rules:\n",
    "- **Strict JSON Output:** The entire response MUST be a single, valid JSON object with no surrounding text or explanations.\n",
    "- **Source Adherence:** Use ONLY the information and PMIDs present in the provided text. Do not infer or add external knowledge.\n",
    "\n",
    "## JSON Schema:\n",
    "{\n",
    "  \"adjuvant\": \"<string>\",\n",
    "  \"summary\": \"<A cohesive, mechanistic narrative of 3-5 sentences describing the sequence of immune events, with inline PMIDs.>\",\n",
    "  \"mechanism_subtypes\": [\n",
    "    {\n",
    "      \"mechanism subtype\": \"<mechanism subtype_1>\",\n",
    "      \"evidence_refs\": [\"########\", \"...\"]\n",
    "    },\n",
    "    {\n",
    "      \"mechanism subtype\": \"<mechanism subtype_2>\",\n",
    "      \"evidence_refs\": [\"########\", \"...\"]\n",
    "    },...\n",
    "  ]\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Load one row from your collapsed CSV\n",
    "df = pd.read_csv(\"Outputs/Vaxjo_PMIDs_adjuvant_mechanism_collapsed.csv\")\n",
    "# Rename the column\n",
    "df = df.rename(columns={\"adjuvant_canonical\": \"adjuvant\"})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de86e88-9023-49f8-91c7-58b84aa82c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the whole DataFrame, run generation, and save raw outputs to a .txt file\n",
    "# Assumes you already have: df, system_prompt, and pipe(...) defined.\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "OUT_TXT = \"Outputs/Vaxjo-LLM-Phase II-Response.txt\"   # plain text (human-readable)\n",
    "# (optional) also keep a machine-friendly JSONL:\n",
    "OUT_JSONL = \"Outputs/Vaxjo-LLM-Phase II-Response.jsonl\"\n",
    "\n",
    "os.makedirs(os.path.dirname(OUT_TXT) or \".\", exist_ok=True)\n",
    "\n",
    "# If you want to change token budget, tweak here:\n",
    "GEN_MAX_NEW_TOKENS = 4028\n",
    "\n",
    "# Open files once and append per row (flush to avoid losing progress mid-run)\n",
    "with open(OUT_TXT, \"w\", encoding=\"utf-8\") as f_txt, open(OUT_JSONL, \"w\", encoding=\"utf-8\") as f_jsonl:\n",
    "    for idx, row in df.iterrows():\n",
    "        adjuvant = str(row.get(\"adjuvant\", \"\"))\n",
    "        mechanism = str(row.get(\"immune_response_mechanism\", \"\"))\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"Adjuvant: {adjuvant}\\nImmune response mechanism:\\n{mechanism}\"}\n",
    "        ]\n",
    "\n",
    "        status = \"ok\"\n",
    "        try:\n",
    "            outputs = pipe(messages, max_new_tokens=GEN_MAX_NEW_TOKENS)\n",
    "            raw = outputs[0][\"generated_text\"][-1][\"content\"]\n",
    "        except Exception as e:\n",
    "            status = \"error\"\n",
    "            raw = f\"__ERROR__: {e}\"\n",
    "\n",
    "        # ---- Write human-readable TXT ----\n",
    "        header = f\"===== ROW {idx} | {adjuvant} | {status} =====\\n\"\n",
    "        f_txt.write(header)\n",
    "        f_txt.write((raw or \"\").strip() + \"\\n\\n\")\n",
    "        f_txt.flush()\n",
    "\n",
    "        # ---- (Optional) also write JSONL per row ----\n",
    "        f_jsonl.write(json.dumps({\n",
    "            \"row_index\": int(idx),\n",
    "            \"adjuvant\": adjuvant,\n",
    "            \"status\": status,\n",
    "            \"raw\": raw\n",
    "        }, ensure_ascii=False) + \"\\n\")\n",
    "        f_jsonl.flush()\n",
    "\n",
    "print(f\"Saved outputs to:\\n- {OUT_TXT}\\n- {OUT_JSONL} (optional JSONL)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c041e713-e2e0-4631-a281-27c110a48d50",
   "metadata": {},
   "source": [
    "##### *Phase II - Processing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785b5199-947b-4847-a9f7-a89c536ffb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "INPUT_FILE = \"Outputs/Vaxjo-LLM-Phase II-Response.txt\" \n",
    "OUTDIR = \"Outputs/final_adjuvant_mechanism_analysis/\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "print(f\"Libraries imported and output directory set to: {OUTDIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb72388-0583-443d-8a88-72b6731f65ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(s: str) -> str:\n",
    "    s = str(s).strip()\n",
    "    s = re.sub(r\"\\bresponses\\b\", \"response\", s, flags=re.I)\n",
    "    s = re.sub(r\"\\bactivations\\b\", \"activation\", s, flags=re.I)\n",
    "    s = re.sub(r\"\\bcells\\b\", \"cell\", s, flags=re.I)\n",
    "    s = re.sub(r\"\\bcytokines\\b\", \"cytokine\", s, flags=re.I)\n",
    "    s = re.sub(r\"\\bantibodies\\b\", \"antibody\", s, flags=re.I)\n",
    "    s = re.sub(r\"\\bpathways\\b\", \"pathway\", s, flags=re.I)\n",
    "    s = re.sub(r\"\\bmechanisms\\b\", \"mechanism\", s, flags=re.I)\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    s = s.replace(\"–\", \"-\").replace(\"—\", \"-\")\n",
    "    # Remove quotes\n",
    "    s = s.replace('\"', \"\").replace(\"'\", \"\")\n",
    "    return s.strip()\n",
    "\n",
    "CANONICAL_REPLACEMENTS = [\n",
    "    (r\"\\bT[- ]?cell\\b\", \"T cell\"),\n",
    "    (r\"\\bTh[- ]?1\\b\", \"Th1\"),\n",
    "    (r\"\\bTh[- ]?2\\b\", \"Th2\"),\n",
    "    (r\"\\bTh[- ]?17\\b\", \"Th17\"),\n",
    "    (r\"\\bIFN ?- ?γ\\b\", \"IFN-γ\"),\n",
    "    (r\"\\bNF.?κB\\b\", \"NF-κB\"),\n",
    "    (r\"\\bB[- ]?cell\\b\", \"B cell\"), \n",
    "]\n",
    "\n",
    "def canonicalize(s: str) -> str:\n",
    "    s = normalize_text(s)\n",
    "    for pat, repl in CANONICAL_REPLACEMENTS:\n",
    "        s = re.sub(pat, repl, s, flags=re.I)\n",
    "    # Force to lowercase for consistent grouping\n",
    "    return s.lower()\n",
    "\n",
    "def restore_acronyms(s: str) -> str:\n",
    "    s = re.sub(r\"\\btlr\\b\", \"TLR\", s, flags=re.I)\n",
    "    s = re.sub(r\"\\bdc\\b\", \"DC\", s, flags=re.I)\n",
    "    s = re.sub(r\"\\bnlrp3\\b\", \"NLRP3\", s, flags=re.I)\n",
    "    s = re.sub(r\"\\bifn\\b\", \"IFN\", s, flags=re.I)\n",
    "    s = re.sub(r\"\\bmhc\\b\", \"MHC\", s, flags=re.I)\n",
    "    s = re.sub(r\"\\bmyd88\\b\", \"MyD88\", s, flags=re.I)\n",
    "    s = re.sub(r\"\\btrif\\b\", \"TRIF\", s, flags=re.I)\n",
    "    s = re.sub(r\"\\bsting\\b\", \"STING\", s, flags=re.I)\n",
    "    return s\n",
    "\n",
    "# [MODIFIED] Map replacement values are now clean and simple\n",
    "ADJUVANT_NORM_MAP = [\n",
    "    # Pattern (regex, case-insensitive)  ->  Canonical Name\n",
    "    # Alum Group\n",
    "    (r\"alum\",                               \"Alum\"),\n",
    "    (r\"aluminium\",                          \"Alum\"),\n",
    "    (r\"aluminum\",                           \"Alum\"),\n",
    "    # Heat-Labile Toxin Group\n",
    "    (r\"\\blt\\b\",                             \"LT\"),\n",
    "    (r\"heat-labile toxin\",                  \"LT\"),\n",
    "    # Freund's Adjuvant\n",
    "    (r\"freund\",                             \"Freund's Adjuvant\"),\n",
    "    (r\"cationic.*liposome\",                 \"Cationic Liposome\"),\n",
    "\n",
    "]\n",
    "\n",
    "def normalize_adjuvant(s: str) -> str:\n",
    "    s = str(s).strip()\n",
    "    \n",
    "    # [MODIFIED] Remove anything in parentheses (e.g., descriptions)\n",
    "    s = re.sub(r\"\\(.*?\\)\", \"\", s).strip()\n",
    "    \n",
    "    s_lower = s.lower()\n",
    "    \n",
    "    for pat, repl in ADJUVANT_NORM_MAP:\n",
    "        if re.search(pat, s_lower, flags=re.I):\n",
    "            return repl\n",
    "    \n",
    "    # If no rule matches, return the new parenthetical-stripped string\n",
    "    return s\n",
    "\n",
    "print(\"All helper functions defined (v4 with corrected map).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6d2397-ba93-4735-9af6-37c28dd2118f",
   "metadata": {},
   "outputs": [],
   "source": [
    "FAMILY_TO_SUBBRANCH = {\n",
    "    # --- 1. SPECIFIC SIGNALING PATHWAYS ---\n",
    "    \"NLRP3 inflammasome activation\": {\n",
    "        \"NLRP3 core branch\": [r\"\\bNLRP3\\b\"],\n",
    "        \"MAPK/JNK pathway\": [r\"\\bMAPK\\b\", r\"\\bJNK\\b\"],\n",
    "        \"Caspase / pyroptosis\": [r\"caspase\", r\"pyroptosis\"],\n",
    "        \"Other inflammasome activity\": [r\"inflammasome\"],\n",
    "    },\n",
    "    \"STING / TRIF / MyD88 / RIG-I signaling\": {\n",
    "        \"STING\": [r\"\\bSTING\\b\"],\n",
    "        \"TRIF\": [r\"\\bTRIF\\b\"],\n",
    "        \"MyD88\": [r\"\\bMyD88\\b\"],\n",
    "        \"RIG-I-like\": [r\"\\bRIG\"],\n",
    "        \"NOD-like\": [r\"\\bNOD\"], \n",
    "        \"Other signaling adaptors\": [r\"adaptor\", r\"signaling\"],\n",
    "    },\n",
    "    \"TLR signaling\": {\n",
    "        \"TLR2 branch\": [r\"\\bTLR2\\b\"],\n",
    "        \"TLR3 branch\": [r\"\\bTLR3\\b\"],\n",
    "        \"TLR4 branch\": [r\"\\bTLR4\\b\"],\n",
    "        \"TLR5 branch\": [r\"\\bTLR5\\b\"],\n",
    "        \"TLR7/8 branch\": [r\"\\bTLR7\\b\", r\"\\bTLR8\\b\"],\n",
    "        \"TLR9 branch\": [r\"\\bTLR9\\b\"],\n",
    "        \"MyD88/TRIF-related\": [r\"MyD88\", r\"TRIF\"], \n",
    "        \"Other TLR-related\": [r\"toll-?like receptor\", r\"\\bTLR\\b\", r\"lipid a\"],\n",
    "    },\n",
    "    \"Pattern recognition / PRR sensing\": {\n",
    "        \"PRR family\": [r\"\\bprr(s)?\\b\"], \n",
    "        \"Pattern recognition\": [r\"pattern recognition\"],\n",
    "        \"C-type lectin receptors\": [r\"Dectin\", r\"Mincle\", r\"\\bMCL\\b\", r\"dc-sign\"],\n",
    "        \"Other pattern sensors\": [r\"recognition\", r\"sensing\", r\"sensors\"],\n",
    "    },\n",
    "    \n",
    "    # --- 2. SPECIFIC CELLULAR RESPONSES ---\n",
    "    \"T cell activation / polarization\": {\n",
    "        \"T cell branch\": [r\"T cell\", r\"T-cell\", r\"T lymphocyte\", r\"\\bctl\\b\", r\"proliferation\"],\n",
    "        \"Th1 branch\": [r\"Th1\"],\n",
    "        \"Th2 branch\": [r\"Th2\"],\n",
    "        \"Th17 branch\": [r\"Th17\"],\n",
    "        \"CD4/CD8 branch\": [r\"CD4\", r\"CD8\"],\n",
    "        \"Tfh branch\": [r\"Tfh\"],\n",
    "        \"Regulatory T cell branch\": [r\"Treg\", r\"regulatory T\"],\n",
    "    },\n",
    "    \"Dendritic cell activation\": {\n",
    "        \"DC maturation\": [r\"maturation\"],\n",
    "        \"DC polarization\": [r\"polarization\"],\n",
    "        \"Plasmacytoid DC\": [r\"plasmacytoid\"],\n",
    "        \"Antigen presentation-related DC\": [r\"antigen\", r\"\\bAPC\\b\", r\"presentation\"],\n",
    "        \"Other DC activation\": [r\"dendritic\"],\n",
    "    },\n",
    "    \"B cell / antibody production\": {\n",
    "        \"B cell activation\": [r\"\\bB cell\\b\", r\"\\bB-cell\\b\"],\n",
    "        \"Antibody production\": [r\"antibody\", r\"\\bIgG\\b\", r\"\\bIgA\\b\", r\"\\bIgM\\b\", r\"\\bIgE\\b\", r\"immunoglobulin\", r\"isotype\"],\n",
    "        \"Humoral immunity\": [r\"humoral\"],\n",
    "        \"Plasma cell / differentiation\": [r\"\\bplasma\\b\", r\"plasmablast\", r\"\\bascs?\\b\"],\n",
    "        \"Germinal center / memory\": [r\"germinal\", r\"memory\"],\n",
    "        \"Other B cell mechanisms\": [r\"\\bB\\b\"],\n",
    "    },\n",
    "    \"Macrophage / innate immune activation\": {\n",
    "        \"Macrophage\": [r\"macrophage\"],\n",
    "        # [MODIFIED] Added 'cd56' (NK cell marker)\n",
    "        \"NK / Monocyte\": [r\"\\bNK\\b\", r\"monocyte\", r\"cd56\"],\n",
    "        \"Innate immune cells\": [r\"innate\"],\n",
    "        \"Neutrophils / Granulocytes\": [r\"neutrophil\", r\"granulocyte\"],\n",
    "        \"Other innate activation\": [r\"activation\"],\n",
    "    },\n",
    "\n",
    "    # --- 3. FUNCTIONAL / PROCESS-BASED ---\n",
    "    \"Antigen presentation / APCs\": {\n",
    "        \"APC activation\": [r\"activation\", r\"\\bAPC\\b\"],\n",
    "        \"Cross-presentation\": [r\"cross-?presentation\", r\"\\bcross\\b\"],\n",
    "        \"MHC / Co-stimulation\": [r\"\\bMHC\\b\", r\"\\bCD40\\b\", r\"\\bCD80\\b\", r\"\\bCD86\\b\", r\"co-?stimul\", r\"b7-2\"],\n",
    "        \"Migration / trafficking\": [r\"migration\", r\"traffick\", r\"recruitment\", r\"leukocyte\"],\n",
    "        \"Antigen processing / uptake\": [r\"antigen\", r\"uptake\", r\"processing\"],\n",
    "        \"Other APC function\": [r\"presentation\"],\n",
    "    },\n",
    "    \"Cytokine signaling / production\": {\n",
    "        \"Interleukins\": [r\"\\bIL[- ]?\\d\", r\"interleukin\"],\n",
    "        \"Interferons\": [r\"\\bIFN\", r\"interferon\"], \n",
    "        \"TNF\": [r\"\\bTNF\"],\n",
    "        \"Chemokines\": [r\"chemokine\", r\"\\bCCL\", r\"\\bCXCL\"],\n",
    "        \"Other cytokines\": [r\"cytokine\"],\n",
    "    },\n",
    "    \"Inflammatory response\": {\n",
    "        \"Pro-inflammatory genes\": [r\"inflamm\", r\"NF[- ]?κB\", r\"NF[- ]?kB\", r\"NFkB\"],\n",
    "        \"Cytokine-mediated inflammation\": [r\"cytokine\"],\n",
    "        \"Chemokine signaling\": [r\"chemokine\", r\"\\bCCL\", r\"\\bCXCL\"],\n",
    "        \"Immune suppression / regulation\": [r\"regulation\", r\"inhibition\"],\n",
    "        \"Other\": [r\"response\", r\"activation\", r\"nitric oxide\", r\"oxidative stress\"],\n",
    "    },\n",
    "\n",
    "    # --- 4. OTHER / HIGH-LEVEL ---\n",
    "    \"Complement / depot / formulation\": {\n",
    "        \"Complement activation\": [r\"complement\"],\n",
    "        \"Depot / release mechanisms\": [r\"depot\", r\"release\"],\n",
    "        \"Adjuvant formulation / emulsions\": [r\"\\balum\\b\", r\"emulsion\", r\"formulation\", r\"oil-in-water\", r\"adsorption\", r\"moisture\"],\n",
    "        \"Other\": [r\"activation\"],\n",
    "    },\n",
    "    \"Adjuvant synergy / immune modulation\": {\n",
    "        \"Immune enhancement\": [r\"enhanc\", r\"promotion\"],\n",
    "        \"Costimulation\": [r\"co-?stimul\", r\"\\bCD40\\b\", r\"\\bCD86\\b\"],\n",
    "        \"Immune modulation\": [r\"modulat\"],\n",
    "        \"Synergy\": [r\"synerg\", r\"combination\", r\"co-?activation\"],\n",
    "        \"Other\": [r\"activation\", r\"retinoic acid\", r\"immunogenicity\"],\n",
    "    },\n",
    "    \"Mucosal immunity\": {\n",
    "        \"Mucosal keywords\": [r\"mucosal\", r\"homing\"],\n",
    "    },\n",
    "    \"Apoptosis / Cell Death Induction\": {\n",
    "        \"Apoptosis keywords\": [r\"apoptosis\", r\"cell death\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "print(f\"Classification map 'FAMILY_TO_SUBBRANCH' defined (v5) with {len(FAMILY_TO_SUBBRANCH)} families.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efb0b62-cf4e-4479-ad5b-c3b1497d7227",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "raw_adjuvants = [] # Store raw adjuvant names\n",
    "raw_subtypes = []  # Store raw subtype names\n",
    "content = \"\" \n",
    "\n",
    "try:\n",
    "    with open(INPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ ERROR: Input file not found: {INPUT_FILE}\")\n",
    "    print(\"Please make sure the file is in the same directory, or provide the full path.\")\n",
    "    # Stop execution if file not found\n",
    "    raise\n",
    "except Exception as e: \n",
    "    print(f\"❌ ERROR: An unexpected error occurred while reading {INPUT_FILE}: {e}\")\n",
    "    # Stop execution if other read error\n",
    "    raise\n",
    "\n",
    "if not content:\n",
    "    print(\"❌ ERROR: File was read but is empty. Cannot proceed.\")\n",
    "else:\n",
    "    # Split the file by the '===== ROW ...' headers\n",
    "    chunks = re.split(r\"===== ROW \\d+ \\| .*? \\| ok =====\", content)\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        if not chunk.strip():\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # Clean up the chunk to get raw JSON\n",
    "            json_text = chunk.strip().strip(\"`\").replace(\"json\", \"\").strip()\n",
    "            \n",
    "            if not json_text.startswith(\"{\"):\n",
    "                print(f\"⚠️ Skipping chunk {i}: No valid JSON object found.\")\n",
    "                continue\n",
    "\n",
    "            inner = json.loads(json_text)\n",
    "            \n",
    "            # --- Adjuvant Normalization ---\n",
    "            adjuvant_raw = inner.get(\"adjuvant\", \"Unknown\").strip()\n",
    "            raw_adjuvants.append(adjuvant_raw) # Store raw\n",
    "            adjuvant = normalize_adjuvant(adjuvant_raw) # Get normalized\n",
    "            #adjuvant = adjuvant_raw # Do not normalize\n",
    "\n",
    "            \n",
    "            for item in inner.get(\"mechanism_subtypes\", []):\n",
    "                # --- Subtype Normalization ---\n",
    "                subtype_raw = item.get(\"mechanism subtype\", \"\")\n",
    "                raw_subtypes.append(subtype_raw) # Store raw\n",
    "                subtype = canonicalize(subtype_raw) # Get normalized\n",
    "                \n",
    "                if subtype:\n",
    "                    records.append({\"Adjuvant\": adjuvant, \"Subtype\": subtype})\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Skipping chunk {i}: Failed to parse JSON. Error: {e}\")\n",
    "\n",
    "    # Create the master DataFrame\n",
    "    df = pd.DataFrame(records)\n",
    "\n",
    "    if df.empty:\n",
    "        print(\"❌ ERROR: No records were successfully parsed. DataFrame is empty.\")\n",
    "        print(\"Please check the INPUT_FILE format.\")\n",
    "    else:\n",
    "        print(f\"✅ Loaded {len(df)} total adjuvant–subtype pairs.\")\n",
    "        \n",
    "        print(\"\\n--- Adjuvant Normalization Stats ---\")\n",
    "        print(f\"   Unique adjuvants BEFORE normalization: {len(set(raw_adjuvants))}\")\n",
    "        print(f\"   Unique adjuvants AFTER normalization:  {df['Adjuvant'].nunique()}\")\n",
    "        \n",
    "        print(\"\\n--- Subtype Normalization Stats ---\")\n",
    "        print(f\"   Unique subtypes BEFORE normalization: {len(set(raw_subtypes))}\")\n",
    "        print(f\"   Unique subtypes AFTER normalization:  {df['Subtype'].nunique()}\")\n",
    "\n",
    "        # Display the first 5 rows\n",
    "        print(\"\\n--- DataFrame Head ---\")\n",
    "        print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4c0de3-895e-42e9-b492-b877a38ef0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_family(sub):\n",
    "    \"\"\"\n",
    "    Iterates through the FAMILY_TO_SUBBRANCH map (from Cell 3)\n",
    "    and returns the first family that matches the subtype.\n",
    "    \"\"\"\n",
    "    for fam, submap in FAMILY_TO_SUBBRANCH.items():\n",
    "        for kws in submap.values():\n",
    "            if any(re.search(kw, sub, flags=re.I) for kw in kws):\n",
    "                return fam\n",
    "    # If no match is found after checking all families\n",
    "    return \"Other / Unclassified\"\n",
    "\n",
    "# Apply the function to the 'Subtype' column to create the new 'Family' column\n",
    "df[\"Family\"] = df[\"Subtype\"].apply(map_to_family)\n",
    "\n",
    "print(\"✅ 'Family' column created successfully.\")\n",
    "\n",
    "# Display the head to show the new column\n",
    "print(\"\\n--- DataFrame Head with 'Family' Column ---\")\n",
    "print(df.head())\n",
    "\n",
    "# Show the distribution of classified families\n",
    "print(\"\\n--- Family Distribution (Top 15) ---\")\n",
    "print(df[\"Family\"].value_counts().head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80992a4a-7794-4c1d-b62a-d08fbcb20cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # 1. Get unique raw adjuvants (from Cell 4)\n",
    "    unique_raw_adjuvants = sorted(list(set(raw_adjuvants)))\n",
    "    df_raw_adj = pd.DataFrame(unique_raw_adjuvants, columns=[\"Raw_Adjuvant_Name\"])\n",
    "    raw_adj_path = os.path.join(OUTDIR, \"review_unique_adjuvants_raw.csv\")\n",
    "    df_raw_adj.to_csv(raw_adj_path, index=False)\n",
    "    print(f\"Saved {len(df_raw_adj)} unique raw adjuvant names to: {raw_adj_path}\")\n",
    "\n",
    "    # 2. Get unique normalized adjuvants (from Cell 4's df)\n",
    "    unique_norm_adjuvants = sorted(list(df[\"Adjuvant\"].unique()))\n",
    "    df_norm_adj = pd.DataFrame(unique_norm_adjuvants, columns=[\"Normalized_Adjuvant_Name\"])\n",
    "    norm_adj_path = os.path.join(OUTDIR, \"review_unique_adjuvants_normalized.csv\")\n",
    "    df_norm_adj.to_csv(norm_adj_path, index=False)\n",
    "    print(f\"Saved {len(df_norm_adj)} unique normalized adjuvant names to: {norm_adj_path}\")\n",
    "\n",
    "    # 3. Get unique raw subtypes (from Cell 4)\n",
    "    unique_raw_subtypes = sorted(list(set(raw_subtypes)))\n",
    "    df_raw_sub = pd.DataFrame(unique_raw_subtypes, columns=[\"Raw_Subtype_Name\"])\n",
    "    raw_sub_path = os.path.join(OUTDIR, \"review_unique_subtypes_raw.csv\")\n",
    "    df_raw_sub.to_csv(raw_sub_path, index=False)\n",
    "    print(f\"Saved {len(df_raw_sub)} unique raw subtype names to: {raw_sub_path}\")\n",
    "\n",
    "    # 4. Get unique normalized subtypes (from Cell 4's df)\n",
    "    unique_norm_subtypes = sorted(list(df[\"Subtype\"].unique()))\n",
    "    df_norm_sub = pd.DataFrame(unique_norm_subtypes, columns=[\"Normalized_Subtype_Name\"])\n",
    "    norm_sub_path = os.path.join(OUTDIR, \"review_unique_subtypes_normalized.csv\")\n",
    "    df_norm_sub.to_csv(norm_sub_path, index=False)\n",
    "    print(f\"Saved {len(df_norm_sub)} unique normalized subtype names to: {norm_sub_path}\")\n",
    "\n",
    "    print(\"\\nAll review files saved.\")\n",
    "\n",
    "except NameError:\n",
    "    print(\"❌ ERROR: Could not find variables 'raw_adjuvants', 'raw_subtypes', or 'df'.\")\n",
    "    print(\"Please make sure you have successfully run Cell 4 and Cell 5.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6204a78-bcaf-4d33-bb58-d941dfdc78f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # 1. Create a binary DataFrame\n",
    "    # This drops all duplicate Adjuvant/Family pairs.\n",
    "    df_binary = df.drop_duplicates(subset=[\"Adjuvant\", \"Family\"])\n",
    "    print(f\"✅ 'df_binary' created. Dropped {len(df) - len(df_binary)} duplicate mentions.\")\n",
    "\n",
    "    # 2. Create the main pivot table (Adjuvant x Family -> Count)\n",
    "    # This will now only have 0s and 1s\n",
    "    pivot = (\n",
    "        df_binary.groupby([\"Adjuvant\", \"Family\"])\n",
    "        .size()\n",
    "        .reset_index(name=\"Count\")\n",
    "    )\n",
    "    \n",
    "    print(\"✅ Binary 'pivot' table created successfully.\")\n",
    "\n",
    "    # 3. Create the family counts for the bar/pie chart\n",
    "    # This now counts the number of ADJUVANTS, not mentions\n",
    "    family_counts = (\n",
    "        pivot.groupby(\"Family\")[\"Count\"]\n",
    "        .sum()\n",
    "        .sort_values(ascending=False)\n",
    "        .reset_index()\n",
    "    )\n",
    "    family_counts.columns = [\"Family\", \"Total_Adjuvants\"] # Renamed column\n",
    "    \n",
    "    print(\"✅ Binary 'family_counts' created successfully.\")\n",
    "    print(\"\\n--- Binary Family Counts Head (Counts Adjuvants, not Mentions) ---\")\n",
    "    print(family_counts.head())\n",
    "\n",
    "    # 4. Save the main pivot table to a CSV\n",
    "    csv_path = os.path.join(OUTDIR, \"adjuvant_family_summary_BINARY.csv\") #&&&&&\n",
    "    pivot.to_csv(csv_path, index=False)\n",
    "    print(f\"\\n🧾 Binary Summary CSV saved → {csv_path}\")\n",
    "\n",
    "except NameError:\n",
    "    print(\"❌ ERROR: Could not find DataFrame 'df'.\")\n",
    "    print(\"Please make sure you have successfully run Cell 4 and Cell 5.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ ERROR: An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b22be76-45d3-4d5f-a382-100cd23daba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # 1. Filter the DataFrame for \"Other / Unclassified\"\n",
    "    df_other = df[df['Family'] == 'Other / Unclassified']\n",
    "    \n",
    "    # 2. Get the unique subtypes\n",
    "    unique_other_count = df_other['Subtype'].nunique()\n",
    "    unique_other_list = sorted(list(df_other['Subtype'].unique()))\n",
    "    \n",
    "    print(f\"✅ Found {unique_other_count} unique subtypes classified as 'Other / Unclassified'.\")\n",
    "    print(f\"   (These {unique_other_count} subtypes appeared a total of {len(df_other)} times)\\n\")\n",
    "    \n",
    "    # 3. Print the list\n",
    "    print(\"--- List of 'Other / Unclassified' Subtypes ---\")\n",
    "    for subtype in unique_other_list:\n",
    "        print(subtype)\n",
    "        \n",
    "    # 4. Save the list to a new CSV for review\n",
    "    df_review_other = pd.DataFrame(unique_other_list, columns=[\"Unclassified_Subtype\"])\n",
    "    other_csv_path = os.path.join(OUTDIR, \"review_unclassified_subtypes.csv\")\n",
    "    df_review_other.to_csv(other_csv_path, index=False)\n",
    "    \n",
    "    print(\"\\n-------------------------------------------------\")\n",
    "    print(f\"🧾 Saved this list for review → {other_csv_path}\")\n",
    "\n",
    "except NameError:\n",
    "    print(\"❌ ERROR: Could not find DataFrame 'df'.\")\n",
    "    print(\"Please make sure you have successfully run Cell 4 and Cell 5.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ ERROR: An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a371f09-7394-4f57-8dd4-de35b58f9b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import plotly.graph_objects as go\n",
    "    import plotly.io as pio\n",
    "except ImportError:\n",
    "    print(\"❌ ERROR: Plotly is not installed. Please run 'pip install plotly kaleido'\")\n",
    "    # You can skip this cell if you don't want the Plotly chart\n",
    "\n",
    "try:\n",
    "    # 1. --- Prepare the DataFrame for Plotly ---\n",
    "    # We use 'family_counts' from Cell 7B\n",
    "    df_plotly = family_counts.copy()\n",
    "    \n",
    "    total = df_plotly[\"Total_Adjuvants\"].sum()\n",
    "    df_plotly[\"percent\"] = (df_plotly[\"Total_Adjuvants\"] / total) * 100\n",
    "    \n",
    "    df_plotly[\"label_text\"] = df_plotly.apply(\n",
    "        lambda row: f\"<b>{restore_acronyms(row['Family'].title())}</b><br>{row['Total_Adjuvants']} Adjuvants ({row['percent']:.1f}%)\",\n",
    "        axis=1\n",
    "    )\n",
    "    df_plotly[\"textposition\"] = df_plotly[\"percent\"].apply(lambda p: 'outside' if p < 5 else 'inside')\n",
    "\n",
    "    print(\"--- Pie Chart Data (Counts Adjuvants) ---\")\n",
    "    print(df_plotly.to_string())\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # 2. --- Build Plotly Pie Chart ---\n",
    "    fig = go.Figure(\n",
    "        data=[\n",
    "            go.Pie(\n",
    "                #labels=df_plotly[\"Family\"].apply(lambda f: restore_acronyms(f.title())),\n",
    "                labels=df_plotly[\"Family\"].apply(restore_acronyms),\n",
    "                values=df_plotly[\"Total_Adjuvants\"],\n",
    "                text=df_plotly[\"label_text\"],\n",
    "                textinfo=\"text\", \n",
    "                textposition=df_plotly[\"textposition\"],\n",
    "                textfont_size=14,\n",
    "                outsidetextfont_size=14,\n",
    "                insidetextorientation=\"radial\", \n",
    "                hovertemplate=\"<b>%{label}</b><br>%{value} Adjuvants<br>%{percent}\",\n",
    "                marker=dict(line=dict(color=\"white\", width=1.5)),\n",
    "                pull=[0.03 if p < 5 else 0 for p in df_plotly[\"percent\"]],\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # 3. --- Layout ---\n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "            text=\"Distribution of Adjuvants across Mechanism Families\", \n",
    "            x=0.5,\n",
    "            font=dict(size=24) \n",
    "        ),\n",
    "        showlegend=False, \n",
    "        width=1200,\n",
    "        height=900,\n",
    "        margin=dict(t=100, b=100, l=100, r=150),\n",
    "    )\n",
    "\n",
    "    # 4. --- Save as HTML file ---\n",
    "    plotly_path = os.path.join(OUTDIR, \"adjuvant_family_pie_interactive.html\")\n",
    "    fig.write_html(plotly_path)\n",
    "    \n",
    "    # 5. --- Save as static image (requires 'kaleido') ---\n",
    "    try:\n",
    "        static_path = os.path.join(OUTDIR, \"adjuvant_family_pie_static.png\")\n",
    "        pio.write_image(fig, static_path, scale=2)\n",
    "        print(f\"📊 Static Plotly pie chart saved → {static_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Could not save static image. (Requires 'kaleido'). Error: {e}\")\n",
    "\n",
    "    print(f\"📊 Interactive Plotly pie chart saved → {plotly_path}\")\n",
    "\n",
    "except NameError:\n",
    "    print(\"❌ ERROR: Could not find 'family_counts' DataFrame.\")\n",
    "    print(\"Please make sure you have successfully run Cell 7B.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ ERROR: An unexpected error occurred while plotting: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f4821d-a6d4-4e3c-a530-613f623aa47e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try    # 1. Find top adjuvants (by mechanistic diversity)\n",
    "    # The .sum() counts the # of families, since 'Count' is always 1\n",
    "    top_adjuvants = pivot.groupby(\"Adjuvant\")[\"Count\"].sum().nlargest(20).index\n",
    "    \n",
    "    # 2. And the top families (by total # of adjuvants)\n",
    "    top_families = family_counts[\"Family\"].head(20) \n",
    "\n",
    "    # 3. Ensure we only select columns that exist after pivoting\n",
    "    valid_families = [f for f in top_families if f in pivot[\"Family\"].unique()]\n",
    "    valid_adjuvants = [a for a in top_adjuvants if a in pivot[\"Adjuvant\"].unique()]\n",
    "\n",
    "    if not valid_families or not valid_adjuvants:\n",
    "        print(\"⚠️ Could not generate heatmap: Not enough valid adjuvants or families.\")\n",
    "    else:\n",
    "        # 4. Build the final heatmap DataFrame from the main 'pivot' table\n",
    "        heatmap_df = (\n",
    "            pivot.pivot_table(index=\"Adjuvant\", columns=\"Family\", values=\"Count\", fill_value=0)\n",
    "            .loc[valid_adjuvants, valid_families]\n",
    "        )\n",
    "        \n",
    "        # 5. Restore acronyms for heatmap labels\n",
    "        heatmap_df.columns = [restore_acronyms(f.title()) for f in heatmap_df.columns]\n",
    "\n",
    "        # [MODIFIED] Use a different colormap for binary (0/1) data\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        sns.heatmap(\n",
    "            heatmap_df,\n",
    "            cmap=\"YlGnBu\", # A good map for 0/1 data\n",
    "            linewidths=0.5,\n",
    "            annot=True, # Will just show 0s and 1s\n",
    "            fmt=\".0f\",\n",
    "            cbar=False # No color bar needed for binary\n",
    "        )\n",
    "        plt.title(\"Top 20 Adjuvants (by Diversity) × Mechanism Families\", fontsize=16, pad=15)\n",
    "        plt.xlabel(\"Mechanism Family\", fontsize=12)\n",
    "        plt.ylabel(\"Adjuvant\", fontsize=12)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.yticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        heatmap_path = os.path.join(OUTDIR, \"adjuvant_family_heatmap.png\")\n",
    "        plt.savefig(heatmap_path, dpi=300)\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"🔥 Heatmap saved → {heatmap_path}\")\n",
    "        print(\"\\nAnalysis complete.\")\n",
    "\n",
    "except NameError:\n",
    "    print(\"❌ ERROR: Could not find 'pivot' or 'family_counts' DataFrames.\")\n",
    "    print(\"Please make sure you have successfully run Cell 7B.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ ERROR: An unexpected error occurred while plotting: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd8ae48-be62-4328-a697-8d3cf0e80407",
   "metadata": {},
   "source": [
    "##### *For latest update of the project please fork https://github.com/hurlab/Vaxjo-LLM* "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Multimodal AI",
   "language": "python",
   "name": "multimodal-ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
