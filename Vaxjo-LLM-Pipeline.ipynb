{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e02f19f-e8b8-461a-a7fd-20e637e8c595",
   "metadata": {},
   "source": [
    "# Phase I: Llama Inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433d82c4-5b21-4196-8ba0-c10392a5451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22eeee3-c37d-4901-9c43-7bc415ef350b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Replace 'your_token_here' with your actual Hugging Face token\n",
    "login(token=\"your_token_here\")\n",
    "\n",
    "print(\"Successfully logged in!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed439a53-8aee-41fa-b42c-f32f95d0463f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_gpus = torch.cuda.device_count()\n",
    "print(\"N GPUS: \", n_gpus)\n",
    "\n",
    "# Set memory limits per GPU\n",
    "model_vram_limit_mib = 8192  #12000\n",
    "max_memory = f'{model_vram_limit_mib}MiB'\n",
    "max_memory_dict = {i: max_memory for i in range(n_gpus)}\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "# Load model and tokenizer with memory limits\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    max_memory=max_memory_dict\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# Now create the pipeline using pre-loaded model/tokenizer\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec775719-b8e0-418d-ba48-6813e94a5aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Custom system prompt for extracting adjuvants and immune mechanisms\n",
    "system_prompt = (\n",
    "        \"\"\"You are a biomedical assistant with expertise in immunology. Extract all substances explicitly described as vaccine adjuvants from the input article.\n",
    "\n",
    "For each adjuvant, extract the following:\n",
    "- \"adjuvant\": The name of the adjuvant (e.g., Alum, MPLA, QS-21)\n",
    "- \"immune_response_mechanism\": A brief description of how the adjuvant works to stimulate or enhance the immune response, as described in the text.\n",
    "\n",
    "Guidelines:\n",
    "- Include only substances that are explicitly described as adjuvants in the input.\n",
    "- Do not include delivery systems (e.g., liposomes, virosomes, VLPs) unless they are clearly described as adjuvants.\n",
    "- Do not infer or guess mechanisms that are not mentioned; leave them empty if not described.\n",
    "- If no adjuvants are found, say 'No adjuvants mentioned.\n",
    "- Return valid JSON in the following format:\n",
    "\n",
    "\n",
    "[\n",
    "  {\n",
    "    \"adjuvant\": \"Alum\",\n",
    "    \"immune_response_mechanism\": \"Activates NLRP3 inflammasome and forms a depot for slow antigen release.\"\n",
    "  },\n",
    "  {\n",
    "    \"adjuvant\": \"MPLA\",\n",
    "    \"immune_response_mechanism\": \"Engages TLR4 pathway to promote Th1 responses.\"\n",
    "  }\n",
    "]\"\"\"\n",
    "    )\n",
    "\n",
    "# Load paper (replace path with your paper path)\n",
    "#with open(\"Dataset/Dataset_PMC_CleanedXML/PMC8707864.xml\", encoding=\"utf-8\") as f:\n",
    "with open(\"Dataset/PMC_Filtered_Reviews_plaintext_gemini/PMC8483762.txt\", encoding=\"utf-8\") as f:\n",
    "    paper_text = f.read()\n",
    "\n",
    "# Create messages in chat format\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": paper_text},\n",
    "]\n",
    "\n",
    "# Run generation\n",
    "outputs = pipe(\n",
    "    messages,\n",
    "    max_new_tokens=256,  # increase if needed\n",
    ")\n",
    "\n",
    "# Print the extracted adjuvant information\n",
    "#print(outputs[0][\"generated_text\"])\n",
    "print(outputs[0][\"generated_text\"][-1][\"content\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1315444e-cac6-40de-9c2f-7802e71cf948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import gc\n",
    "from datetime import datetime\n",
    "\n",
    "def extract_and_save_adjuvant_response_text_from_string(\n",
    "    pmc_id: str,\n",
    "    text: str,\n",
    "    system_prompt: str,\n",
    "    pipe,\n",
    "    output_file: str,\n",
    "    max_new_tokens: int = 512\n",
    "):\n",
    "    \"\"\"\n",
    "    Processes a single abstract string and saves the response with PMID to output_file.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": text},\n",
    "    ]\n",
    "    outputs = pipe(messages, max_new_tokens=max_new_tokens)\n",
    "    response_text = outputs[0][\"generated_text\"][-1][\"content\"]\n",
    "    with open(output_file, \"a\", encoding=\"utf-8\") as out_f:\n",
    "        out_f.write(f\"=== {pmc_id} ===\\n\")\n",
    "        out_f.write(response_text.strip() + \"\\n\\n\")\n",
    "    print(f\"Saved response for {pmc_id} to {output_file}\")\n",
    "\n",
    "def process_all_papers(\n",
    "    input_json_file: str,\n",
    "    system_prompt: str,\n",
    "    pipe,\n",
    "    output_txt_file: str,\n",
    "    log_csv_file: str,\n",
    "    max_new_tokens: int = 512\n",
    "):\n",
    "    \"\"\"\n",
    "    Processes all abstracts from a JSON file and logs each result (success/failure) to a CSV.\n",
    "    Args:\n",
    "        input_json_file (str): Path to input JSON file with {PMID: {title, abstract}} entries.\n",
    "        system_prompt (str): System prompt for the LLM.\n",
    "        pipe: Hugging Face pipeline object.\n",
    "        output_txt_file (str): Path to save model responses (plain text).\n",
    "        log_csv_file (str): Path to save logs (CSV).\n",
    "        max_new_tokens (int): Generation token limit.\n",
    "    \"\"\"\n",
    "    # Read all abstracts into a dict\n",
    "    with open(input_json_file, encoding=\"utf-8\") as f:\n",
    "        papers_dict = json.load(f)\n",
    "\n",
    "    print(f\"Found {len(papers_dict)} papers. Starting extraction...\\n\")\n",
    "\n",
    "    # Prepare log CSV (write headers if file doesn't exist)\n",
    "    log_exists = os.path.exists(log_csv_file)\n",
    "    with open(log_csv_file, \"a\", newline='', encoding=\"utf-8\") as log_f:\n",
    "        log_writer = csv.writer(log_f)\n",
    "        if not log_exists:\n",
    "            log_writer.writerow([\"PMID\", \"Status\", \"Message\", \"Timestamp\"])\n",
    "\n",
    "        for i, (pmcid, paper_data) in enumerate(papers_dict.items(), 1):\n",
    "            abstract_text = paper_data.get(\"abstract\", \"\") or \"\"\n",
    "            status = \"success\"\n",
    "            message = \"Processed successfully\"\n",
    "            try:\n",
    "                extract_and_save_adjuvant_response_text_from_string(\n",
    "                    pmcid, abstract_text, system_prompt, pipe, output_txt_file, max_new_tokens\n",
    "                )\n",
    "            except Exception as e:\n",
    "                status = \"error\"\n",
    "                message = str(e)[:500]\n",
    "                print(f\"❌ Error processing PMID {pmcid}: {message}\")\n",
    "            else:\n",
    "                print(f\"✅ [{i}/{len(papers_dict)}] Processed PMID {pmcid}\")\n",
    "            finally:\n",
    "                log_writer.writerow([pmcid, status, message, datetime.now().isoformat()])\n",
    "                log_f.flush()\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2254c2da-5b5c-48ff-b617-5a1ac88c410a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import csv\n",
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "input_json_file = \"Dataset/Vaxjo/All PMID abstracts.txt\"  # should contain JSON, not plain text\n",
    "output_txt_file = \"Outputs/Vaxjo_PMIDs_adjuvant_responses.txt\"\n",
    "log_csv_file = \"Outputs/Vaxjo_PMIDs_adjuvant_log.csv\"\n",
    "\n",
    "process_all_papers(\n",
    "    input_json_file,\n",
    "    system_prompt,\n",
    "    pipe,\n",
    "    output_txt_file,\n",
    "    log_csv_file,\n",
    "    max_new_tokens=512\n",
    ")\n",
    "print(\"Phase I LLM inferencing complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f68ed98-f32e-4a75-8703-c21a84da9511",
   "metadata": {},
   "source": [
    "# Intermediate Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea56db01-8ae6-4775-b786-b042d2f3b31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load the content from the text file\n",
    "with open(\"Outputs/Vaxjo_PMIDs_adjuvant_responses.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Extract each PMID block\n",
    "entries = re.split(r'===\\s+(\\d+)\\s+===', content)[1:]\n",
    "pmid_ids = entries[::2]   # PMIDs\n",
    "texts = entries[1::2]    # Corresponding text blocks\n",
    "\n",
    "# Extract data\n",
    "data = []\n",
    "for pmid_id, text in zip(pmid_ids, texts):\n",
    "    if \"No adjuvants mentioned.\" in text:\n",
    "        continue\n",
    "    # Find JSON-like blocks\n",
    "    json_blocks = re.findall(r\"\\[\\s*{.*?}\\s*]\", text, re.DOTALL)\n",
    "    for block in json_blocks:\n",
    "        try:\n",
    "            adjuvant_list = json.loads(block)\n",
    "            for item in adjuvant_list:\n",
    "                data.append({\n",
    "                    \"PMID\": pmid_id,\n",
    "                    \"adjuvant\": item.get(\"adjuvant\"),\n",
    "                    \"immune_response_mechanism\": item.get(\"immune_response_mechanism\")\n",
    "                })\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "\n",
    "# Save to CSV\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"Outputs/Vaxjo_PMIDs_adjuvant_extracted.csv\", index=False)\n",
    "\n",
    "print(\"Extraction complete. Saved to 'Vaxjo_PMIDs_adjuvant_extracted.csv'.\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31655c42-f643-4f18-9a28-6dc1bfc8ce5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique adjuvants\n",
    "unique_adjuvants = df[\"adjuvant\"].nunique()\n",
    "print(f\"Number of unique adjuvants: {unique_adjuvants}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d782dd3d-f00f-44f6-ae62-8960946e0f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find unique immune response mechanisms containing the word \"not\" (case-insensitive)\n",
    "mechanisms = df[\"immune_response_mechanism\"].dropna().unique()\n",
    "\n",
    "mechanisms_with_not_none = [\n",
    "    m for m in mechanisms if (\"not \" in m.lower() or \"none \" in m.lower() in m.lower())\n",
    "]\n",
    "\n",
    "for mechanism in mechanisms_with_not_none:\n",
    "    print(mechanism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d37069b-ed3c-483e-96cb-50c206e5581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_valid_keywords = [\n",
    "    \"None mentioned\",\n",
    "\"Not explicitly described\",\n",
    "\"None mentioned.\",\n",
    "\"Not specified\",\n",
    "\"None described\",\n",
    "\"Not explicitly described in the text\",\n",
    "\"Mechanism of action not yet completely known, but it is comprised of Quillaja saponins, cholesterol and phospholipid, and induces recruitment of leukocytes to draining lymph nodes (dLNs) and spleen, activation of central immune cells, and elevation of cytokines and co-stimulatory molecules.\",\n",
    "\"None specified\",\n",
    "\"Not mentioned\",\n",
    "\"Mechanism not explicitly described\",\n",
    "\"Not explicitly stated, but based on the context, it appears to stimulate a robust immune response by enhancing the production of various cytokines and antibody-secreting cells.\",\n",
    "\"Not specified in the text.\",\n",
    "\"Not explicitly described, but it is known that aluminum salts activate NLRP3 inflammasome and form a depot for slow antigen release.\",\n",
    "\"Not explicitly described, but it is known that saponins like QS21 can stimulate immune responses by interacting with TLR4 and TLR8.\",\n",
    "\"Not described\",\n",
    "\"Mechanism not described\",\n",
    "\"Not explicitly described, left blank.\"\n",
    "]\n",
    "\n",
    "\n",
    "# Drop rows with NaN or empty strings (after stripping whitespace)\n",
    "df_cleaned = df[df[\"immune_response_mechanism\"].notna()].copy()\n",
    "df_cleaned = df_cleaned[df_cleaned[\"immune_response_mechanism\"].str.strip() != \"\"]\n",
    "\n",
    "# Remove rows containing any invalid keyword (case-insensitive)\n",
    "df_cleaned = df_cleaned[\n",
    "    ~df_cleaned[\"immune_response_mechanism\"].str.lower().apply(\n",
    "        lambda x: any(keyword in x for keyword in not_valid_keywords)\n",
    "    )\n",
    "].reset_index(drop=True)\n",
    "\n",
    "# Save to CSV\n",
    "df_cleaned.to_csv(\"Outputs/Vaxjo_PMIDs_adjuvant_extracted_clean.csv\", index=False)\n",
    "\n",
    "# Preview the result\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736515bd-2cee-4bc2-9939-06151aa352c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and print the sorted list of unique adjuvant names\n",
    "unique_adjuvant_names = sorted(df_cleaned[\"adjuvant\"].unique())\n",
    "print(\"Unique adjuvants:\")\n",
    "for name in unique_adjuvant_names:\n",
    "    print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dd6539-fc6b-4081-965e-da60e0736c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    # ---- Adjuplex / ADJ ----\n",
    "    \"ADJ\": \"Adjuplex (ADJ)\",\n",
    "\n",
    "    # ---- Alum / Aluminum hydroxide family (exact naming variants only) ----\n",
    "    \"Alum\": \"Alum (aluminum hydroxide)\",\n",
    "    \"Al(OH)3\": \"Alum (aluminum hydroxide)\",\n",
    "    \"Alhydrogel\": \"Alum (aluminum hydroxide)\", #commercial brand name for an aluminum hydroxide gel suspension\n",
    "    \"Aluminium Hydroxide (AH)\": \"Alum (aluminum hydroxide)\",\n",
    "    \"Aluminium hydroxide\": \"Alum (aluminum hydroxide)\",\n",
    "    \"Aluminum Hydroxide\": \"Alum (aluminum hydroxide)\",\n",
    "    \"Aluminum Hydroxide (AH)\": \"Alum (aluminum hydroxide)\",\n",
    "    \"Aluminum hydroxide\": \"Alum (aluminum hydroxide)\",\n",
    "    \"Aluminum hydroxide (AH)\": \"Alum (aluminum hydroxide)\",\n",
    "    \"Aluminum hydroxide (Alum)\": \"Alum (aluminum hydroxide)\",\n",
    "    \"Aluminum oxyhydroxide\": \"Alum (aluminum hydroxide)\", #Aluminum oxyhydroxide is the formal chemical name for the hydrated crystalline species often used in alum adjuvants (sometimes cited as boehmite-like AlO(OH)), which is the same active form as in common alum formulations. So mapping to “Alum (aluminum hydroxide)” is also correct.\n",
    "    # ---- Advax / delta inulin (brand vs generic, diacritics, ™/®) ----\n",
    "    \"Advax\": \"Advax (delta inulin)\",\n",
    "    \"Advax delta inulin\": \"Advax (delta inulin)\",\n",
    "    \"Advax® delta inulin\": \"Advax (delta inulin)\",\n",
    "    \"Advax™\": \"Advax (delta inulin)\",\n",
    "    \"Delta Inulin (DI)\": \"Advax (delta inulin)\",\n",
    "    \"Delta inulin\": \"Advax (delta inulin)\",\n",
    "    \"delta inulin\": \"Advax (delta inulin)\",\n",
    "    \"delta inulin (DI)\": \"Advax (delta inulin)\",\n",
    "    \"delta inulin adjuvant (Advax™)\": \"Advax (delta inulin)\",\n",
    "    \"δ-inulin\": \"Advax (delta inulin)\",\n",
    "    \"delta-inulin\": \"Advax (delta inulin)\",\n",
    "\n",
    "    # Keep specific Advax *formulations* distinct:\n",
    "    # Advax-2 / -M / -P / -SM / CpG / CpG55.2 etc. are NOT collapsed.\n",
    "\n",
    "    # ---- BECC spelling/spacing ----\n",
    "    \"BECC 438\": \"BECC438\",\n",
    "    \"BECC 470\": \"BECC470\",\n",
    "\n",
    "    # ---- Calcium phosphate shorthand ----\n",
    "    \"CAP\": \"Calcium Phosphate (CAP)\",\n",
    "\n",
    "    # ---- CAF01 encoding variant ----\n",
    "    \"CAF\\u00b01\": \"CAF01\",\n",
    "\n",
    "    # ---- Cholera toxin naming ----\n",
    "    \"Cholera toxin\": \"Cholera toxin (CT)\",\n",
    "\n",
    "    # ---- Compound 48/80 naming ----\n",
    "    \"C48/80\": \"Compound 48/80 (C48/80)\",\n",
    "\n",
    "    # ---- CoVaccine HT trademark ----\n",
    "    \"CoVaccine HT™\": \"CoVaccine HT\",\n",
    "\n",
    "    # ---- CpG ODN (shorthands & plurals used as the same thing here) ----\n",
    "    \"CpG\": \"CpG ODN\",\n",
    "    \"CpG ODNs\": \"CpG ODN\",\n",
    "    #\"CpG motifs\": \"CpG ODN\",\n",
    "    \"CpG oligodeoxynucleotide (CpG-ODN)\": \"CpG ODN\",\n",
    "    \"CpG-ODN\": \"CpG ODN\",\n",
    "\n",
    "    # Keep specific sequences distinct (not collapsed):\n",
    "    # \"CpG ODN 1826\", \"CpG M362\", \"ODN2006\" remain separate.\n",
    "\n",
    "\n",
    "    \"Complete Freund's adjuvant\": \"Complete Freund's Adjuvant (CFA)\",\n",
    "    \n",
    "    # ---- EM-005 aka GLA-SE ----\n",
    "    \"EM-005 (GLA-SE)\": \"GLA-SE\",\n",
    "\n",
    "    # ---- Flagellin (case only) ----\n",
    "    \"flagellin\": \"Flagellin\",\n",
    "\n",
    "    # (FliC, FlaB kept distinct—specific flagellins.)\n",
    "\n",
    "    # ---- GLA naming variants ----\n",
    "    \"Glucopyranosyl Lipid Adjuvant\": \"GLA\",\n",
    "    \"Glucopyranosyl Lipid Adjuvant (GLA)\": \"GLA\",\n",
    "    \"Glucopyranosyl lipid A\": \"GLA\",\n",
    "    #\"Glucopyranosyl lipid A (G100)\": \"GLA\",\n",
    "    \"Glucopyranosyl lipid adjuvant (GLA)\": \"GLA\",\n",
    "    \"ID93/glucopyranosyl lipid adjuvant (GLA)\": \"GLA\",\n",
    "    # GLA-AF / GLA-SE / GLA-LSQ are formulations—kept distinct.\n",
    "    \n",
    "    \"GLA-SE (components included: glucopyranosyl lipid A, squalene emulsion)\": \"GLA-SE\",\n",
    "    \"GLA-squalene emulsion\": \"GLA-SE\",\n",
    "    \"Glucopyranosyl lipid A (G100)\": \"GLA\",\n",
    "    \n",
    "    # ---- IFN naming (alpha/beta symbol) ----\n",
    "    \"IFN-alpha\": \"IFN-α\",\n",
    "    \"IFNβ\": \"IFN-β\",\n",
    "\n",
    "    # ---- Imiquimod alias ----\n",
    "    \"imiquimod (R837)\": \"Imiquimod (R837)\",\n",
    "    \"Imiquimod\": \"Imiquimod (R837)\",\n",
    "\n",
    "    # ---- Matrix-M trademark ----\n",
    "    \"Matrix-M™\": \"Matrix-M\",\n",
    "\n",
    "    # ---- MCT trademark ----\n",
    "    \"MCT®\": \"MCT\",\n",
    "\n",
    "    # ---- MPL naming variants ----\n",
    "    '''\"MPL\": \"MPL (monophosphoryl lipid A)\",\n",
    "    \"MPL®\": \"MPL (monophosphoryl lipid A)\",\n",
    "    \"Monophosphoryl lipid\": \"MPL (monophosphoryl lipid A)\",\n",
    "    \"Monophosphoryl lipid A (MPLA)\": \"MPLA\",'''\n",
    "    \n",
    "    # Keep \"MPLA\" as is (canonical already).\n",
    "    \"MPL\": \"MPL (monophosphoryl lipid A)\",\n",
    "    \"MPL®\": \"MPL (monophosphoryl lipid A)\",\n",
    "    \"Monophosphoryl lipid\": \"MPL (monophosphoryl lipid A)\",\n",
    "    \"Monophosphoryl lipid A (MPLA)\": \"MPL (monophosphoryl lipid A)\",\n",
    "\n",
    "    \"MPL (monophosphoryl lipid A)\": \"MPLA\",\n",
    "    \"MPL\": \"MPLA\",   # redundant safety check, in case not yet mapped\n",
    "    \n",
    "    # \"MPLA\" stays as is (already canonical).\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"M7\": \"Mastoparan-7 (M7)\",\n",
    "\n",
    "    \n",
    "    # Keep MPL-SE / MPL+TDM / MPL/DDA distinct (formulations/combinations).\n",
    "\n",
    "    # ---- Montanide ISA 51 spacing ----\n",
    "    \"Montanide ISA-51\": \"Montanide ISA 51\",\n",
    "    \"Montanide ISA51\": \"Montanide ISA 51\",\n",
    "    \n",
    "    # --- Mastoparan naming ---\n",
    "    \"Mastoparan 7\": \"Mastoparan-7 (M7)\",\n",
    "   \n",
    "    # ---- PCL abbreviation expansion ----\n",
    "    \"PCL/chitosan NPs\": \"poly-ϵ-caprolactone/chitosan NPs\",\n",
    "\n",
    "    # ---- Poly(I:C) case ----\n",
    "    \"poly(I:C)\": \"Poly(I:C)\",\n",
    "\n",
    "    # ---- Polyclonal Antibody Stimulator naming ----\n",
    "    \"polyclonal antibody stimulator-PAS\": \"Polyclonal Antibody Stimulator (PAS)\",\n",
    "\n",
    "    # ---- QS-21 dash/spacing ----\n",
    "    \"QS21\": \"QS-21\",\n",
    "\n",
    "    # ---- R848 (resiquimod) alias ----\n",
    "    \"R848\": \"Resiquimod (R848)\",\n",
    "    \"resiquimod\": \"Resiquimod (R848)\",\n",
    "\n",
    "    # ---- SE (squalene emulsion) naming (keep brands separate like MF59/AS03) ----\n",
    "    \"Squalene-based oil-in-water emulsion system (SE)\": \"SE\",\n",
    "    \"squalene oil-in-water emulsion (SE)\": \"SE\",\n",
    "\n",
    "    # ---- SWE (Sepivac SWE) naming ----\n",
    "    \"Sepivac SWE\": \"SWE\",\n",
    "    \"SEPIVAC SWETM\": \"SWE\",\n",
    "\n",
    "    # ---- Squalene case only ----\n",
    "    \"squalene\": \"Squalene\",\n",
    "\n",
    "    # ---- TDM (trehalose-6,6'-dimycolate) spelling variants ----\n",
    "    \"6,6'-trehalose dimycolate (TDM)\": \"Trehalose-6,6'-dimycolate (TDM)\",\n",
    "\n",
    "    # ---- α-GalCer naming variants ----\n",
    "    \"α-Galactosylceramide (α-GC)\": \"α-GalCer\",\n",
    "    \"α-Galactosylceramide (αGalCer)\": \"α-GalCer\",\n",
    "}\n",
    "df_cleaned[\"adjuvant_canonical\"] = df_cleaned[\"adjuvant\"].replace(mapping)\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc417b3f-0179-4f6b-b9be-1ff172ca9637",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before:\", df_cleaned[\"adjuvant\"].nunique())\n",
    "print(\"After :\", df_cleaned[\"adjuvant_canonical\"].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dc4204-16d5-47f3-8eaf-6eaaf88d7a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and print the sorted list of unique adjuvant names\n",
    "unique_adjuvant_names_canonical = sorted(df_cleaned[\"adjuvant_canonical\"].unique())\n",
    "print(\"Unique adjuvants_canonical:\")\n",
    "for name in unique_adjuvant_names_canonical:\n",
    "    print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12c0d9c-5009-40cd-8acf-fb1b0bbe3641",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = (\n",
    "    df_cleaned\n",
    "    .assign(immune_response_mechanism=lambda x: x[\"immune_response_mechanism\"] + \" [\" + x[\"PMID\"].astype(str) + \"]\")\n",
    "    .groupby(\"adjuvant_canonical\")[\"immune_response_mechanism\"]\n",
    "    .agg(lambda x: \" | \".join(sorted(set(x))))\n",
    "    .reset_index()\n",
    "    .sort_values(by=\"adjuvant_canonical\", key=lambda s: s.str.lower())\n",
    ")\n",
    "\n",
    "df_grouped.to_csv(\"Outputs/Vaxjo_PMIDs_adjuvant_mechanism_collapsed.csv\", index=False)\n",
    "df_grouped\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c77bbb4-c509-4983-88f1-4f05e58cd692",
   "metadata": {},
   "source": [
    "# # Phase II: Llama Inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd478aa-0613-4cb7-bf08-51e37d9d4bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "system_prompt = \"\"\"You are an expert immunologist and biomedical research assistant.\n",
    "TASK: Analyze the provided text on a vaccine adjuvant's immune response. Extract and structure the key mechanistic information according to the specified JSON schema.\n",
    "\n",
    "## Instructions for the \"summary\" field:\n",
    "- **Synthesize the information into a cohesive, mechanistic narrative of approximately 3-5 sentences.**\n",
    "- This summary should not be a simple list of facts. Instead, it should describe the sequence of immunological events initiated by the adjuvant.\n",
    "- For example, describe how the adjuvant is initially sensed (e.g., by PRRs like TLRs), how this leads to innate cell activation (e.g., dendritic cells), and how this subsequently shapes the adaptive response (e.g., T cell polarization and antibody production).\n",
    "- Integrate the corresponding PMIDs directly into the text immediately following the claims they support.\n",
    "\n",
    "## Instructions for the \"mechanism_subtypes\" field:\n",
    "- Identify **every distinct** immunological mechanism.\n",
    "- For each identified subtype, list all unique PMIDs cited as evidence for it in the source text.\n",
    "- Do not merge related subtypes; for example, if both \"dendritic cell\" and \"TLR4\" are mentioned, create separate entries for each.\n",
    "\n",
    "## General Rules:\n",
    "- **Strict JSON Output:** The entire response MUST be a single, valid JSON object with no surrounding text or explanations.\n",
    "- **Source Adherence:** Use ONLY the information and PMIDs present in the provided text. Do not infer or add external knowledge.\n",
    "\n",
    "## JSON Schema:\n",
    "{\n",
    "  \"adjuvant\": \"<string>\",\n",
    "  \"summary\": \"<A cohesive, mechanistic narrative of 3-5 sentences describing the sequence of immune events, with inline PMIDs.>\",\n",
    "  \"mechanism_subtypes\": [\n",
    "    {\n",
    "      \"mechanism subtype\": \"<mechanism subtype_1>\",\n",
    "      \"evidence_refs\": [\"########\", \"...\"]\n",
    "    },\n",
    "    {\n",
    "      \"mechanism subtype\": \"<mechanism subtype_2>\",\n",
    "      \"evidence_refs\": [\"########\", \"...\"]\n",
    "    },...\n",
    "  ]\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Load one row from your collapsed CSV\n",
    "df = pd.read_csv(\"Outputs/Vaxjo_PMIDs_adjuvant_mechanism_collapsed.csv\")\n",
    "# Rename the column\n",
    "df = df.rename(columns={\"adjuvant_canonical\": \"adjuvant\"})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de86e88-9023-49f8-91c7-58b84aa82c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the whole DataFrame, run generation, and save raw outputs to a .txt file\n",
    "# Assumes you already have: df, system_prompt, and pipe(...) defined.\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "OUT_TXT = \"Outputs/Vaxjo_PMIDs_mechanism_summary_raw_outputs_llama3.2.txt\"   # plain text (human-readable)\n",
    "# (optional) also keep a machine-friendly JSONL:\n",
    "OUT_JSONL = \"Outputs/Vaxjo_PMIDs_mechanism_summary_raw_outputs_llama3.2.jsonl\"\n",
    "\n",
    "os.makedirs(os.path.dirname(OUT_TXT) or \".\", exist_ok=True)\n",
    "\n",
    "# If you want to change token budget, tweak here:\n",
    "GEN_MAX_NEW_TOKENS = 4028\n",
    "\n",
    "# Open files once and append per row (flush to avoid losing progress mid-run)\n",
    "with open(OUT_TXT, \"w\", encoding=\"utf-8\") as f_txt, open(OUT_JSONL, \"w\", encoding=\"utf-8\") as f_jsonl:\n",
    "    for idx, row in df.iterrows():\n",
    "        adjuvant = str(row.get(\"adjuvant\", \"\"))\n",
    "        mechanism = str(row.get(\"immune_response_mechanism\", \"\"))\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"Adjuvant: {adjuvant}\\nImmune response mechanism:\\n{mechanism}\"}\n",
    "        ]\n",
    "\n",
    "        status = \"ok\"\n",
    "        try:\n",
    "            outputs = pipe(messages, max_new_tokens=GEN_MAX_NEW_TOKENS)\n",
    "            raw = outputs[0][\"generated_text\"][-1][\"content\"]\n",
    "        except Exception as e:\n",
    "            status = \"error\"\n",
    "            raw = f\"__ERROR__: {e}\"\n",
    "\n",
    "        # ---- Write human-readable TXT ----\n",
    "        header = f\"===== ROW {idx} | {adjuvant} | {status} =====\\n\"\n",
    "        f_txt.write(header)\n",
    "        f_txt.write((raw or \"\").strip() + \"\\n\\n\")\n",
    "        f_txt.flush()\n",
    "\n",
    "        # ---- (Optional) also write JSONL per row ----\n",
    "        f_jsonl.write(json.dumps({\n",
    "            \"row_index\": int(idx),\n",
    "            \"adjuvant\": adjuvant,\n",
    "            \"status\": status,\n",
    "            \"raw\": raw\n",
    "        }, ensure_ascii=False) + \"\\n\")\n",
    "        f_jsonl.flush()\n",
    "\n",
    "print(f\"Saved outputs to:\\n- {OUT_TXT}\\n- {OUT_JSONL} (optional JSONL)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284b5747-fa21-48ad-bf70-d7b96b0ccccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3dca35-b2c5-4ba9-b355-81063b6bb967",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
